{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [ (\"big data\", 100, 15), (\"Hadoop\", 95, 25), (\"Python\", 75, 50), (\"R\", 50, 40), (\"machine learning\", 80, 20), (\"statistics\", 20, 60), (\"data science\", 60, 70), (\"analytics\", 90, 3), (\"team player\", 85, 85), (\"dynamic\", 2, 90), (\"synergies\", 70, 0), (\"actionable insights\", 40, 30), (\"think out of the box\", 45, 10), (\"self-starter\", 30, 50), (\"customer focus\", 65, 15), (\"thought leadership\", 35, 35), (\"team player\", 85, 85), (\"dynamic\", 2, 90), (\"synergies\", 70, 0), (\"actionable insights\", 40, 30), (\"think out of the box\", 45, 10), (\"self-starter\", 30, 50), (\"customer focus\", 65, 15), (\"thought leadership\", 35, 35)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math, random, re\n",
    "from collections import defaultdict, Counter\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "def text_size(total):\n",
    "    return 8 + total / 200 * 20\n",
    "\n",
    "for word, job_pop, res_pop in data:\n",
    "    plt.text(job_pop, res_pop, word, ha='center', va='center', size = text_size(job_pop + res_pop))\n",
    "plt.xlabel(\"Popularity on Job Postings\")\n",
    "plt.ylabel(\"Popularity on Resumes\")\n",
    "plt.axis([0, 100, 0, 100])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"We've\",\n",
       " 'all',\n",
       " 'heard',\n",
       " 'it',\n",
       " 'according',\n",
       " 'to',\n",
       " 'Hal',\n",
       " 'Varian',\n",
       " 'statistics',\n",
       " 'is',\n",
       " 'the',\n",
       " 'next',\n",
       " 'sexy',\n",
       " 'job',\n",
       " '.',\n",
       " 'Five',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'in',\n",
       " 'What',\n",
       " 'is',\n",
       " 'Web',\n",
       " '2',\n",
       " '.',\n",
       " '0',\n",
       " 'Tim',\n",
       " \"O'Reilly\",\n",
       " 'said',\n",
       " 'that',\n",
       " 'data',\n",
       " 'is',\n",
       " 'the',\n",
       " 'next',\n",
       " 'Intel',\n",
       " 'Inside',\n",
       " '.',\n",
       " 'But',\n",
       " 'what',\n",
       " 'does',\n",
       " 'that',\n",
       " 'statement',\n",
       " 'mean',\n",
       " 'Why',\n",
       " 'do',\n",
       " 'we',\n",
       " 'suddenly',\n",
       " 'care',\n",
       " 'about',\n",
       " 'statistics',\n",
       " 'and',\n",
       " 'about',\n",
       " 'data',\n",
       " 'In',\n",
       " 'this',\n",
       " 'post',\n",
       " 'I',\n",
       " 'examine',\n",
       " 'the',\n",
       " 'many',\n",
       " 'sides',\n",
       " 'of',\n",
       " 'data',\n",
       " 'science',\n",
       " 'the',\n",
       " 'technologies',\n",
       " 'the',\n",
       " 'companies',\n",
       " 'and',\n",
       " 'the',\n",
       " 'unique',\n",
       " 'skill',\n",
       " 'sets',\n",
       " '.',\n",
       " 'The',\n",
       " 'web',\n",
       " 'is',\n",
       " 'full',\n",
       " 'of',\n",
       " 'data',\n",
       " 'driven',\n",
       " 'apps',\n",
       " '.',\n",
       " 'Almost',\n",
       " 'any',\n",
       " 'e',\n",
       " 'commerce',\n",
       " 'application',\n",
       " 'is',\n",
       " 'a',\n",
       " 'data',\n",
       " 'driven',\n",
       " 'application',\n",
       " '.',\n",
       " \"There's\",\n",
       " 'a',\n",
       " 'database',\n",
       " 'behind',\n",
       " 'a',\n",
       " 'web',\n",
       " 'front',\n",
       " 'end',\n",
       " 'and',\n",
       " 'middleware',\n",
       " 'that',\n",
       " 'talks',\n",
       " 'to',\n",
       " 'a',\n",
       " 'number',\n",
       " 'of',\n",
       " 'other',\n",
       " 'databases',\n",
       " 'and',\n",
       " 'data',\n",
       " 'services',\n",
       " 'credit',\n",
       " 'card',\n",
       " 'processing',\n",
       " 'companies',\n",
       " 'banks',\n",
       " 'and',\n",
       " 'so',\n",
       " 'on',\n",
       " '.',\n",
       " 'But',\n",
       " 'merely',\n",
       " 'using',\n",
       " 'data',\n",
       " \"isn't\",\n",
       " 'really',\n",
       " 'what',\n",
       " 'we',\n",
       " 'mean',\n",
       " 'by',\n",
       " 'data',\n",
       " 'science',\n",
       " '.',\n",
       " 'A',\n",
       " 'data',\n",
       " 'application',\n",
       " 'acquires',\n",
       " 'its',\n",
       " 'value',\n",
       " 'from',\n",
       " 'the',\n",
       " 'data',\n",
       " 'itself',\n",
       " 'and',\n",
       " 'creates',\n",
       " 'more',\n",
       " 'data',\n",
       " 'as',\n",
       " 'a',\n",
       " 'result',\n",
       " '.',\n",
       " \"It's\",\n",
       " 'not',\n",
       " 'just',\n",
       " 'an',\n",
       " 'application',\n",
       " 'with',\n",
       " 'data',\n",
       " \"it's\",\n",
       " 'a',\n",
       " 'data',\n",
       " 'product',\n",
       " '.',\n",
       " 'Data',\n",
       " 'science',\n",
       " 'enables',\n",
       " 'the',\n",
       " 'creation',\n",
       " 'of',\n",
       " 'data',\n",
       " 'products',\n",
       " '.',\n",
       " 'One',\n",
       " 'of',\n",
       " 'the',\n",
       " 'earlier',\n",
       " 'data',\n",
       " 'products',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Web',\n",
       " 'was',\n",
       " 'the',\n",
       " 'CDDB',\n",
       " 'database',\n",
       " '.',\n",
       " 'The',\n",
       " 'developers',\n",
       " 'of',\n",
       " 'CDDB',\n",
       " 'realized',\n",
       " 'that',\n",
       " 'any',\n",
       " 'CD',\n",
       " 'had',\n",
       " 'a',\n",
       " 'unique',\n",
       " 'signature',\n",
       " 'based',\n",
       " 'on',\n",
       " 'the',\n",
       " 'exact',\n",
       " 'length',\n",
       " 'in',\n",
       " 'samples',\n",
       " 'of',\n",
       " 'each',\n",
       " 'track',\n",
       " 'on',\n",
       " 'the',\n",
       " 'CD',\n",
       " '.',\n",
       " 'Gracenote',\n",
       " 'built',\n",
       " 'a',\n",
       " 'database',\n",
       " 'of',\n",
       " 'track',\n",
       " 'lengths',\n",
       " 'and',\n",
       " 'coupled',\n",
       " 'it',\n",
       " 'to',\n",
       " 'a',\n",
       " 'database',\n",
       " 'of',\n",
       " 'album',\n",
       " 'metadata',\n",
       " 'track',\n",
       " 'titles',\n",
       " 'artists',\n",
       " 'album',\n",
       " 'titles',\n",
       " '.',\n",
       " 'If',\n",
       " \"you've\",\n",
       " 'ever',\n",
       " 'used',\n",
       " 'iTunes',\n",
       " 'to',\n",
       " 'rip',\n",
       " 'a',\n",
       " 'CD',\n",
       " \"you've\",\n",
       " 'taken',\n",
       " 'advantage',\n",
       " 'of',\n",
       " 'this',\n",
       " 'database',\n",
       " '.',\n",
       " 'Before',\n",
       " 'it',\n",
       " 'does',\n",
       " 'anything',\n",
       " 'else',\n",
       " 'iTunes',\n",
       " 'reads',\n",
       " 'the',\n",
       " 'length',\n",
       " 'of',\n",
       " 'every',\n",
       " 'track',\n",
       " 'sends',\n",
       " 'it',\n",
       " 'to',\n",
       " 'CDDB',\n",
       " 'and',\n",
       " 'gets',\n",
       " 'back',\n",
       " 'the',\n",
       " 'track',\n",
       " 'titles',\n",
       " '.',\n",
       " 'If',\n",
       " 'you',\n",
       " 'have',\n",
       " 'a',\n",
       " 'CD',\n",
       " \"that's\",\n",
       " 'not',\n",
       " 'in',\n",
       " 'the',\n",
       " 'database',\n",
       " 'including',\n",
       " 'a',\n",
       " 'CD',\n",
       " \"you've\",\n",
       " 'made',\n",
       " 'yourself',\n",
       " 'you',\n",
       " 'can',\n",
       " 'create',\n",
       " 'an',\n",
       " 'entry',\n",
       " 'for',\n",
       " 'an',\n",
       " 'unknown',\n",
       " 'album',\n",
       " '.',\n",
       " 'While',\n",
       " 'this',\n",
       " 'sounds',\n",
       " 'simple',\n",
       " 'enough',\n",
       " \"it's\",\n",
       " 'revolutionary',\n",
       " 'CDDB',\n",
       " 'views',\n",
       " 'music',\n",
       " 'as',\n",
       " 'data',\n",
       " 'not',\n",
       " 'as',\n",
       " 'audio',\n",
       " 'and',\n",
       " 'creates',\n",
       " 'new',\n",
       " 'value',\n",
       " 'in',\n",
       " 'doing',\n",
       " 'so',\n",
       " '.',\n",
       " 'Their',\n",
       " 'business',\n",
       " 'is',\n",
       " 'fundamentally',\n",
       " 'different',\n",
       " 'from',\n",
       " 'selling',\n",
       " 'music',\n",
       " 'sharing',\n",
       " 'music',\n",
       " 'or',\n",
       " 'analyzing',\n",
       " 'musical',\n",
       " 'tastes',\n",
       " 'though',\n",
       " 'these',\n",
       " 'can',\n",
       " 'also',\n",
       " 'be',\n",
       " 'data',\n",
       " 'products',\n",
       " '.',\n",
       " 'CDDB',\n",
       " 'arises',\n",
       " 'entirely',\n",
       " 'from',\n",
       " 'viewing',\n",
       " 'a',\n",
       " 'musical',\n",
       " 'problem',\n",
       " 'as',\n",
       " 'a',\n",
       " 'data',\n",
       " 'problem',\n",
       " '.',\n",
       " 'Google',\n",
       " 'is',\n",
       " 'a',\n",
       " 'master',\n",
       " 'at',\n",
       " 'creating',\n",
       " 'data',\n",
       " 'products',\n",
       " '.',\n",
       " \"Here's\",\n",
       " 'a',\n",
       " 'few',\n",
       " 'examples',\n",
       " 'Google',\n",
       " \"isn't\",\n",
       " 'the',\n",
       " 'only',\n",
       " 'company',\n",
       " 'that',\n",
       " 'knows',\n",
       " 'how',\n",
       " 'to',\n",
       " 'use',\n",
       " 'data',\n",
       " '.',\n",
       " 'Facebook',\n",
       " 'and',\n",
       " 'LinkedIn',\n",
       " 'use',\n",
       " 'patterns',\n",
       " 'of',\n",
       " 'friendship',\n",
       " 'relationships',\n",
       " 'to',\n",
       " 'suggest',\n",
       " 'other',\n",
       " 'people',\n",
       " 'you',\n",
       " 'may',\n",
       " 'know',\n",
       " 'or',\n",
       " 'should',\n",
       " 'know',\n",
       " 'with',\n",
       " 'sometimes',\n",
       " 'frightening',\n",
       " 'accuracy',\n",
       " '.',\n",
       " 'Amazon',\n",
       " 'saves',\n",
       " 'your',\n",
       " 'searches',\n",
       " 'correlates',\n",
       " 'what',\n",
       " 'you',\n",
       " 'search',\n",
       " 'for',\n",
       " 'with',\n",
       " 'what',\n",
       " 'other',\n",
       " 'users',\n",
       " 'search',\n",
       " 'for',\n",
       " 'and',\n",
       " 'uses',\n",
       " 'it',\n",
       " 'to',\n",
       " 'create',\n",
       " 'surprisingly',\n",
       " 'appropriate',\n",
       " 'recommendations',\n",
       " '.',\n",
       " 'These',\n",
       " 'recommendations',\n",
       " 'are',\n",
       " 'data',\n",
       " 'products',\n",
       " 'that',\n",
       " 'help',\n",
       " 'to',\n",
       " 'drive',\n",
       " \"Amazon's\",\n",
       " 'more',\n",
       " 'traditional',\n",
       " 'retail',\n",
       " 'business',\n",
       " '.',\n",
       " 'They',\n",
       " 'come',\n",
       " 'about',\n",
       " 'because',\n",
       " 'Amazon',\n",
       " 'understands',\n",
       " 'that',\n",
       " 'a',\n",
       " 'book',\n",
       " \"isn't\",\n",
       " 'just',\n",
       " 'a',\n",
       " 'book',\n",
       " 'a',\n",
       " 'camera',\n",
       " \"isn't\",\n",
       " 'just',\n",
       " 'a',\n",
       " 'camera',\n",
       " 'and',\n",
       " 'a',\n",
       " 'customer',\n",
       " \"isn't\",\n",
       " 'just',\n",
       " 'a',\n",
       " 'customer',\n",
       " 'customers',\n",
       " 'generate',\n",
       " 'a',\n",
       " 'trail',\n",
       " 'of',\n",
       " 'data',\n",
       " 'exhaust',\n",
       " 'that',\n",
       " 'can',\n",
       " 'be',\n",
       " 'mined',\n",
       " 'and',\n",
       " 'put',\n",
       " 'to',\n",
       " 'use',\n",
       " 'and',\n",
       " 'a',\n",
       " 'camera',\n",
       " 'is',\n",
       " 'a',\n",
       " 'cloud',\n",
       " 'of',\n",
       " 'data',\n",
       " 'that',\n",
       " 'can',\n",
       " 'be',\n",
       " 'correlated',\n",
       " 'with',\n",
       " 'the',\n",
       " \"customers'\",\n",
       " 'behavior',\n",
       " 'the',\n",
       " 'data',\n",
       " 'they',\n",
       " 'leave',\n",
       " 'every',\n",
       " 'time',\n",
       " 'they',\n",
       " 'visit',\n",
       " 'the',\n",
       " 'site',\n",
       " '.',\n",
       " 'The',\n",
       " 'thread',\n",
       " 'that',\n",
       " 'ties',\n",
       " 'most',\n",
       " 'of',\n",
       " 'these',\n",
       " 'applications',\n",
       " 'together',\n",
       " 'is',\n",
       " 'that',\n",
       " 'data',\n",
       " 'collected',\n",
       " 'from',\n",
       " 'users',\n",
       " 'provides',\n",
       " 'added',\n",
       " 'value',\n",
       " '.',\n",
       " 'Whether',\n",
       " 'that',\n",
       " 'data',\n",
       " 'is',\n",
       " 'search',\n",
       " 'terms',\n",
       " 'voice',\n",
       " 'samples',\n",
       " 'or',\n",
       " 'product',\n",
       " 'reviews',\n",
       " 'the',\n",
       " 'users',\n",
       " 'are',\n",
       " 'in',\n",
       " 'a',\n",
       " 'feedback',\n",
       " 'loop',\n",
       " 'in',\n",
       " 'which',\n",
       " 'they',\n",
       " 'contribute',\n",
       " 'to',\n",
       " 'the',\n",
       " 'products',\n",
       " 'they',\n",
       " 'use',\n",
       " '.',\n",
       " \"That's\",\n",
       " 'the',\n",
       " 'beginning',\n",
       " 'of',\n",
       " 'data',\n",
       " 'science',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'last',\n",
       " 'few',\n",
       " 'years',\n",
       " 'there',\n",
       " 'has',\n",
       " 'been',\n",
       " 'an',\n",
       " 'explosion',\n",
       " 'in',\n",
       " 'the',\n",
       " 'amount',\n",
       " 'of',\n",
       " 'data',\n",
       " \"that's\",\n",
       " 'available',\n",
       " '.',\n",
       " 'Whether',\n",
       " \"we're\",\n",
       " 'talking',\n",
       " 'about',\n",
       " 'web',\n",
       " 'server',\n",
       " 'logs',\n",
       " 'tweet',\n",
       " 'streams',\n",
       " 'online',\n",
       " 'transaction',\n",
       " 'records',\n",
       " 'citizen',\n",
       " 'science',\n",
       " 'data',\n",
       " 'from',\n",
       " 'sensors',\n",
       " 'government',\n",
       " 'data',\n",
       " 'or',\n",
       " 'some',\n",
       " 'other',\n",
       " 'source',\n",
       " 'the',\n",
       " 'problem',\n",
       " \"isn't\",\n",
       " 'finding',\n",
       " 'data',\n",
       " \"it's\",\n",
       " 'figuring',\n",
       " 'out',\n",
       " 'what',\n",
       " 'to',\n",
       " 'do',\n",
       " 'with',\n",
       " 'it',\n",
       " '.',\n",
       " 'And',\n",
       " \"it's\",\n",
       " 'not',\n",
       " 'just',\n",
       " 'companies',\n",
       " 'using',\n",
       " 'their',\n",
       " 'own',\n",
       " 'data',\n",
       " 'or',\n",
       " 'the',\n",
       " 'data',\n",
       " 'contributed',\n",
       " 'by',\n",
       " 'their',\n",
       " 'users',\n",
       " '.',\n",
       " \"It's\",\n",
       " 'increasingly',\n",
       " 'common',\n",
       " 'to',\n",
       " 'mashup',\n",
       " 'data',\n",
       " 'from',\n",
       " 'a',\n",
       " 'number',\n",
       " 'of',\n",
       " 'sources',\n",
       " '.',\n",
       " 'Data',\n",
       " 'Mashups',\n",
       " 'in',\n",
       " 'R',\n",
       " 'analyzes',\n",
       " 'mortgage',\n",
       " 'foreclosures',\n",
       " 'in',\n",
       " 'Philadelphia',\n",
       " 'County',\n",
       " 'by',\n",
       " 'taking',\n",
       " 'a',\n",
       " 'public',\n",
       " 'report',\n",
       " 'from',\n",
       " 'the',\n",
       " 'county',\n",
       " \"sheriff's\",\n",
       " 'office',\n",
       " 'extracting',\n",
       " 'addresses',\n",
       " 'and',\n",
       " 'using',\n",
       " 'Yahoo',\n",
       " 'to',\n",
       " 'convert',\n",
       " 'the',\n",
       " 'addresses',\n",
       " 'to',\n",
       " 'latitude',\n",
       " 'and',\n",
       " 'longitude',\n",
       " 'then',\n",
       " 'using',\n",
       " 'the',\n",
       " 'geographical',\n",
       " 'data',\n",
       " 'to',\n",
       " 'place',\n",
       " 'the',\n",
       " 'foreclosures',\n",
       " 'on',\n",
       " 'a',\n",
       " 'map',\n",
       " 'another',\n",
       " 'data',\n",
       " 'source',\n",
       " 'and',\n",
       " 'group',\n",
       " 'them',\n",
       " 'by',\n",
       " 'neighborhood',\n",
       " 'valuation',\n",
       " 'neighborhood',\n",
       " 'per',\n",
       " 'capita',\n",
       " 'income',\n",
       " 'and',\n",
       " 'other',\n",
       " 'socio',\n",
       " 'economic',\n",
       " 'factors',\n",
       " '.',\n",
       " 'The',\n",
       " 'question',\n",
       " 'facing',\n",
       " 'every',\n",
       " 'company',\n",
       " 'today',\n",
       " 'every',\n",
       " 'startup',\n",
       " 'every',\n",
       " 'non',\n",
       " 'profit',\n",
       " 'every',\n",
       " 'project',\n",
       " 'site',\n",
       " 'that',\n",
       " 'wants',\n",
       " 'to',\n",
       " 'attract',\n",
       " 'a',\n",
       " 'community',\n",
       " 'is',\n",
       " 'how',\n",
       " 'to',\n",
       " 'use',\n",
       " 'data',\n",
       " 'effectively',\n",
       " 'not',\n",
       " 'just',\n",
       " 'their',\n",
       " 'own',\n",
       " 'data',\n",
       " 'but',\n",
       " 'all',\n",
       " 'the',\n",
       " 'data',\n",
       " \"that's\",\n",
       " 'available',\n",
       " 'and',\n",
       " 'relevant',\n",
       " '.',\n",
       " 'Using',\n",
       " 'data',\n",
       " 'effectively',\n",
       " 'requires',\n",
       " 'something',\n",
       " 'different',\n",
       " 'from',\n",
       " 'traditional',\n",
       " 'statistics',\n",
       " 'where',\n",
       " 'actuaries',\n",
       " 'in',\n",
       " 'business',\n",
       " 'suits',\n",
       " 'perform',\n",
       " 'arcane',\n",
       " 'but',\n",
       " 'fairly',\n",
       " 'well',\n",
       " 'defined',\n",
       " 'kinds',\n",
       " 'of',\n",
       " 'analysis',\n",
       " '.',\n",
       " 'What',\n",
       " 'differentiates',\n",
       " 'data',\n",
       " 'science',\n",
       " 'from',\n",
       " 'statistics',\n",
       " 'is',\n",
       " 'that',\n",
       " 'data',\n",
       " 'science',\n",
       " 'is',\n",
       " 'a',\n",
       " 'holistic',\n",
       " 'approach',\n",
       " '.',\n",
       " \"We're\",\n",
       " 'increasingly',\n",
       " 'finding',\n",
       " 'data',\n",
       " 'in',\n",
       " 'the',\n",
       " 'wild',\n",
       " 'and',\n",
       " 'data',\n",
       " 'scientists',\n",
       " 'are',\n",
       " 'involved',\n",
       " 'with',\n",
       " 'gathering',\n",
       " 'data',\n",
       " 'massaging',\n",
       " 'it',\n",
       " 'into',\n",
       " 'a',\n",
       " 'tractable',\n",
       " 'form',\n",
       " 'making',\n",
       " 'it',\n",
       " 'tell',\n",
       " 'its',\n",
       " 'story',\n",
       " 'and',\n",
       " 'presenting',\n",
       " 'that',\n",
       " 'story',\n",
       " 'to',\n",
       " 'others',\n",
       " '.',\n",
       " 'To',\n",
       " 'get',\n",
       " 'a',\n",
       " 'sense',\n",
       " 'for',\n",
       " 'what',\n",
       " 'skills',\n",
       " 'are',\n",
       " 'required',\n",
       " \"let's\",\n",
       " 'look',\n",
       " 'at',\n",
       " 'the',\n",
       " 'data',\n",
       " 'lifecycle',\n",
       " 'where',\n",
       " 'it',\n",
       " 'comes',\n",
       " 'from',\n",
       " 'how',\n",
       " 'you',\n",
       " 'use',\n",
       " 'it',\n",
       " 'and',\n",
       " 'where',\n",
       " 'it',\n",
       " 'goes',\n",
       " '.',\n",
       " 'Data',\n",
       " 'is',\n",
       " 'everywhere',\n",
       " 'your',\n",
       " 'government',\n",
       " 'your',\n",
       " 'web',\n",
       " 'server',\n",
       " 'your',\n",
       " 'business',\n",
       " 'partners',\n",
       " 'even',\n",
       " 'your',\n",
       " 'body',\n",
       " '.',\n",
       " 'While',\n",
       " 'we',\n",
       " \"aren't\",\n",
       " 'drowning',\n",
       " 'in',\n",
       " 'a',\n",
       " 'sea',\n",
       " 'of',\n",
       " 'data',\n",
       " \"we're\",\n",
       " 'finding',\n",
       " 'that',\n",
       " 'almost',\n",
       " 'everything',\n",
       " 'can',\n",
       " 'or',\n",
       " 'has',\n",
       " 'been',\n",
       " 'instrumented',\n",
       " '.',\n",
       " 'At',\n",
       " \"O'Reilly\",\n",
       " 'we',\n",
       " 'frequently',\n",
       " 'combine',\n",
       " 'publishing',\n",
       " 'industry',\n",
       " 'data',\n",
       " 'from',\n",
       " 'Nielsen',\n",
       " 'BookScan',\n",
       " 'with',\n",
       " 'our',\n",
       " 'own',\n",
       " 'sales',\n",
       " 'data',\n",
       " 'publicly',\n",
       " 'available',\n",
       " 'Amazon',\n",
       " 'data',\n",
       " 'and',\n",
       " 'even',\n",
       " 'job',\n",
       " 'data',\n",
       " 'to',\n",
       " 'see',\n",
       " \"what's\",\n",
       " 'happening',\n",
       " 'in',\n",
       " 'the',\n",
       " 'publishing',\n",
       " 'industry',\n",
       " '.',\n",
       " 'Sites',\n",
       " 'like',\n",
       " 'Infochimps',\n",
       " 'and',\n",
       " 'Factual',\n",
       " 'provide',\n",
       " 'access',\n",
       " 'to',\n",
       " 'many',\n",
       " 'large',\n",
       " 'datasets',\n",
       " 'including',\n",
       " 'climate',\n",
       " 'data',\n",
       " 'MySpace',\n",
       " 'activity',\n",
       " 'streams',\n",
       " 'and',\n",
       " 'game',\n",
       " 'logs',\n",
       " 'from',\n",
       " 'sporting',\n",
       " 'events',\n",
       " '.',\n",
       " 'Factual',\n",
       " 'enlists',\n",
       " 'users',\n",
       " 'to',\n",
       " 'update',\n",
       " 'and',\n",
       " 'improve',\n",
       " 'its',\n",
       " 'datasets',\n",
       " 'which',\n",
       " 'cover',\n",
       " 'topics',\n",
       " 'as',\n",
       " 'diverse',\n",
       " 'as',\n",
       " 'endocrinologists',\n",
       " 'to',\n",
       " 'hiking',\n",
       " 'trails',\n",
       " '.',\n",
       " 'Much',\n",
       " 'of',\n",
       " 'the',\n",
       " 'data',\n",
       " 'we',\n",
       " 'currently',\n",
       " 'work',\n",
       " 'with',\n",
       " 'is',\n",
       " 'the',\n",
       " 'direct',\n",
       " 'consequence',\n",
       " 'of',\n",
       " 'Web',\n",
       " '2',\n",
       " '.',\n",
       " '0',\n",
       " 'and',\n",
       " 'of',\n",
       " \"Moore's\",\n",
       " 'Law',\n",
       " 'applied',\n",
       " 'to',\n",
       " 'data',\n",
       " '.',\n",
       " 'The',\n",
       " 'web',\n",
       " 'has',\n",
       " 'people',\n",
       " 'spending',\n",
       " 'more',\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fix_unicode(text):\n",
    "     return text.replace(u\"\\u2019\", \"'\")\n",
    "def get_document():\n",
    "    url = \"http://radar.oreilly.com/2010/06/what-is-data-science.html\"\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, 'html5lib')\n",
    "\n",
    "    content = soup.find(\"div\", \"article-body\")         # find article-body div\n",
    "    regex = r\"[\\w']+|[\\.]\"                             # matches a word or a period\n",
    "\n",
    "    document = []\n",
    "\n",
    " \n",
    "    for paragraph in content(\"p\"):\n",
    "        words = re.findall(regex, fix_unicode(paragraph.text))\n",
    "        document.extend(words)\n",
    "\n",
    "    return document\n",
    "document=get_document()\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = zip(document, document[1:])\n",
    "transitions = defaultdict(list)\n",
    "for key, value in bigrams:\n",
    "     transitions[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It started out just spent a lot of data science the data .'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_using_bigrams():\n",
    "    current = \".\"\n",
    "    result = []\n",
    "    while True:\n",
    "        next_word_candidates = transitions[current]\n",
    "        current = random.choice(next_word_candidates)\n",
    "        result.append(current)\n",
    "        if current == \".\":\n",
    "            return \" \".join(result)\n",
    "generate_using_bigrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = zip(document, document[1:], document[2:])\n",
    "trigram_transitions = defaultdict(list)\n",
    "starts = []\n",
    "for prev, current, next in trigrams:\n",
    "    if prev == \".\": # if the previous \"word\" was a period\n",
    "           starts.append(current) # then this is a start word\n",
    "    trigram_transitions[(prev, current)].append(next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Much of the data .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_using_trigrams():\n",
    "    current = random.choice(starts) # choose a random starting word\n",
    "    prev = \".\" # and precede it with a '.'\n",
    "    result = [current]\n",
    "    while True:\n",
    "        next_word_candidates = trigram_transitions[(prev, current)]\n",
    "        next_word = random.choice(next_word_candidates)\n",
    "        prev, current = current, next_word\n",
    "        result.append(current)\n",
    "        if current == \".\":\n",
    "            return \" \".join(result)\n",
    "generate_using_trigrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = {\n",
    " \"_S\" : [\"_NP _VP\"],\n",
    " \"_NP\" : [\"_N\",\n",
    " \"_A _NP _P _A _N\"],\n",
    " \"_VP\" : [\"_V\",\n",
    " \"_V _NP\"],\n",
    " \"_N\" : [\"data science\", \"Python\", \"regression\"],\n",
    " \"_A\" : [\"big\", \"linear\", \"logistic\"],\n",
    " \"_P\" : [\"about\", \"near\"],\n",
    " \"_V\" : [\"learns\", \"trains\", \"tests\", \"is\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_terminal(token):\n",
    "    return token[0] != \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(grammar, tokens):\n",
    "    for i, token in enumerate(tokens):\n",
    "        if is_terminal(token): continue\n",
    "        replacement = random.choice(grammar[token])\n",
    "        if is_terminal(replacement):\n",
    "            tokens[i] = replacement\n",
    "        else:\n",
    "            tokens = tokens[:i] + replacement.split() + tokens[(i+1):]\n",
    "        return expand(grammar, tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(grammar):\n",
    "    return expand(grammar, [\"_S\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python', 'is']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def roll_a_die():\n",
    "    return random.choice([1,2,3,4,5,6])\n",
    "roll_a_die()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def direct_sample():\n",
    "    d1 = roll_a_die()\n",
    "    d2 = roll_a_die()\n",
    "    return d1, d1 + d2\n",
    "direct_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_y_given_x(x):\n",
    "    \"\"\"equally likely to be x + 1, x + 2, ... , x + 6\"\"\"\n",
    "    return x + roll_a_die()\n",
    "random_y_given_x(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_x_given_y(y):\n",
    "    if y <= 7:\n",
    "        return random.randrange(1, y)\n",
    "    else:\n",
    "        return random.randrange(y - 6, 7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_x_given_y(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_x_given_y(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_sample(num_iters=100):\n",
    "    x, y = 1, 2\n",
    "    for _ in range(num_iters):\n",
    "        x = random_x_given_y(y)\n",
    "        y = random_y_given_x(x)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gibbs_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_distributions(num_samples=1000):\n",
    "    counts = defaultdict(lambda: [0, 0])\n",
    "    for _ in range(num_samples):\n",
    "        counts[gibbs_sample()][0] += 1\n",
    "        counts[direct_sample()][1] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.compare_distributions.<locals>.<lambda>()>,\n",
       "            {(6, 10): [32, 30],\n",
       "             (2, 8): [31, 26],\n",
       "             (4, 10): [30, 17],\n",
       "             (6, 7): [43, 30],\n",
       "             (3, 7): [32, 32],\n",
       "             (3, 6): [22, 25],\n",
       "             (5, 8): [26, 36],\n",
       "             (5, 6): [21, 31],\n",
       "             (2, 6): [23, 32],\n",
       "             (1, 7): [38, 27],\n",
       "             (6, 11): [28, 26],\n",
       "             (2, 7): [31, 28],\n",
       "             (3, 8): [30, 27],\n",
       "             (5, 10): [24, 24],\n",
       "             (2, 5): [25, 20],\n",
       "             (1, 5): [17, 19],\n",
       "             (3, 9): [19, 34],\n",
       "             (4, 8): [27, 26],\n",
       "             (1, 2): [39, 35],\n",
       "             (1, 3): [34, 24],\n",
       "             (2, 4): [19, 29],\n",
       "             (5, 11): [23, 30],\n",
       "             (4, 6): [33, 26],\n",
       "             (5, 9): [31, 21],\n",
       "             (3, 4): [20, 31],\n",
       "             (4, 5): [29, 30],\n",
       "             (1, 4): [30, 34],\n",
       "             (4, 9): [35, 35],\n",
       "             (2, 3): [29, 24],\n",
       "             (6, 9): [21, 27],\n",
       "             (1, 6): [24, 20],\n",
       "             (5, 7): [29, 32],\n",
       "             (3, 5): [20, 31],\n",
       "             (6, 8): [27, 30],\n",
       "             (4, 7): [33, 30],\n",
       "             (6, 12): [25, 21]})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_distributions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from(weights):\n",
    "    total = sum(weights)\n",
    "    rnd = total * random.random() # uniform between 0 and total\n",
    "    for i, w in enumerate(weights):\n",
    "        rnd -= w # return the smallest i such that\n",
    "        if rnd <= 0: return i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_from([1, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "        [\"Hadoop\", \"Big Data\", \"HBase\", \"Java\", \"Spark\", \"Storm\", \"Cassandra\"],\n",
    "        [\"NoSQL\", \"MongoDB\", \"Cassandra\", \"HBase\", \"Postgres\"],\n",
    "        [\"Python\", \"scikit-learn\", \"scipy\", \"numpy\", \"statsmodels\", \"pandas\"],\n",
    "        [\"R\", \"Python\", \"statistics\", \"regression\", \"probability\"],\n",
    "        [\"machine learning\", \"regression\", \"decision trees\", \"libsvm\"],\n",
    "        [\"Python\", \"R\", \"Java\", \"C++\", \"Haskell\", \"programming languages\"],\n",
    "        [\"statistics\", \"probability\", \"mathematics\", \"theory\"],\n",
    "        [\"machine learning\", \"scikit-learn\", \"Mahout\", \"neural networks\"],\n",
    "        [\"neural networks\", \"deep learning\", \"Big Data\", \"artificial intelligence\"],\n",
    "        [\"Hadoop\", \"Java\", \"MapReduce\", \"Big Data\"],\n",
    "        [\"statistics\", \"R\", \"statsmodels\"],\n",
    "        [\"C++\", \"deep learning\", \"artificial intelligence\", \"probability\"],\n",
    "        [\"pandas\", \"R\", \"Python\"],\n",
    "        [\"databases\", \"HBase\", \"Postgres\", \"MySQL\", \"MongoDB\"],\n",
    "        [\"libsvm\", \"regression\", \"support vector machines\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_topic_counts = [Counter() for _ in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter(), Counter(), Counter(), Counter()]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 4\n",
    "topic_word_counts = [Counter() for _ in range(K)]\n",
    "topic_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_counts = [0 for _ in range(K)]\n",
    "topic_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 5, 6, 5, 4, 6, 4, 4, 4, 4, 3, 4, 3, 5, 3]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_lengths = list(map(len, documents))\n",
    "document_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_words = set(word for document in documents for word in document)\n",
    "W = len(distinct_words)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Big Data',\n",
       " 'C++',\n",
       " 'Cassandra',\n",
       " 'HBase',\n",
       " 'Hadoop',\n",
       " 'Haskell',\n",
       " 'Java',\n",
       " 'Mahout',\n",
       " 'MapReduce',\n",
       " 'MongoDB',\n",
       " 'MySQL',\n",
       " 'NoSQL',\n",
       " 'Postgres',\n",
       " 'Python',\n",
       " 'R',\n",
       " 'Spark',\n",
       " 'Storm',\n",
       " 'artificial intelligence',\n",
       " 'databases',\n",
       " 'decision trees',\n",
       " 'deep learning',\n",
       " 'libsvm',\n",
       " 'machine learning',\n",
       " 'mathematics',\n",
       " 'neural networks',\n",
       " 'numpy',\n",
       " 'pandas',\n",
       " 'probability',\n",
       " 'programming languages',\n",
       " 'regression',\n",
       " 'scikit-learn',\n",
       " 'scipy',\n",
       " 'statistics',\n",
       " 'statsmodels',\n",
       " 'support vector machines',\n",
       " 'theory'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = len(documents)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_topic_counts[3][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word_counts[2][\"nlp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_topic_given_document(topic, d, alpha=0.1):\n",
    "    return ((document_topic_counts[d][topic] + alpha) /\n",
    "            (document_lengths[d] + K * alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_word_given_topic(word, topic, beta=0.1):\n",
    "    return ((topic_word_counts[topic][word] + beta) /\n",
    "            (topic_counts[topic] + W * beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_weight(d, word, k):\n",
    "    return p_word_given_topic(word, k) * p_topic_given_document(k, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_new_topic(d, word):\n",
    "    return sample_from([topic_weight(d, word, k)\n",
    "        for k in range(K)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "document_topics = [[random.randrange(K) for word in document]\n",
    "    for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range(D):\n",
    "    for word, topic in zip(documents[d], document_topics[d]):\n",
    "        document_topic_counts[d][topic] += 1\n",
    "        topic_word_counts[topic][word] += 1\n",
    "        topic_counts[topic] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range(1000):\n",
    "    for d in range(D):\n",
    "        for i, (word, topic) in enumerate(zip(documents[d],\n",
    "                                             document_topics[d])):\n",
    "            # remove this word / topic from the counts\n",
    "            # so that it doesn't influence the weights\n",
    "            document_topic_counts[d][topic] -= 1\n",
    "            topic_word_counts[topic][word] -= 1\n",
    "            topic_counts[topic] -= 1\n",
    "            document_lengths[d] -= 1\n",
    "\n",
    "            # choose a new topic based on the weights\n",
    "            new_topic = choose_new_topic(d, word)\n",
    "            document_topics[d][i] = new_topic\n",
    "\n",
    "            # and now add it back to the counts\n",
    "            document_topic_counts[d][new_topic] += 1\n",
    "            topic_word_counts[new_topic][word] += 1\n",
    "            topic_counts[new_topic] += 1\n",
    "            document_lengths[d] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 regression 2\n",
      "0 libsvm 2\n",
      "0 machine learning 2\n",
      "0 neural networks 2\n",
      "0 scikit-learn 1\n",
      "0 support vector machines 1\n",
      "0 probability 1\n",
      "0 Mahout 1\n",
      "0 mathematics 1\n",
      "1 Postgres 2\n",
      "1 MongoDB 2\n",
      "1 Cassandra 1\n",
      "1 MySQL 1\n",
      "1 artificial intelligence 1\n",
      "1 C++ 1\n",
      "2 Java 3\n",
      "2 HBase 3\n",
      "2 Big Data 3\n",
      "2 Hadoop 2\n",
      "2 Cassandra 1\n",
      "2 C++ 1\n",
      "2 artificial intelligence 1\n",
      "2 NoSQL 1\n",
      "2 Spark 1\n",
      "2 Storm 1\n",
      "2 Haskell 1\n",
      "2 programming languages 1\n",
      "2 MapReduce 1\n",
      "2 databases 1\n",
      "3 Python 4\n",
      "3 R 4\n",
      "3 statistics 3\n",
      "3 probability 2\n",
      "3 deep learning 2\n",
      "3 pandas 2\n",
      "3 statsmodels 2\n",
      "3 decision trees 1\n",
      "3 theory 1\n",
      "3 regression 1\n",
      "3 scipy 1\n",
      "3 scikit-learn 1\n",
      "3 numpy 1\n"
     ]
    }
   ],
   "source": [
    "for k, word_counts in enumerate(topic_word_counts):\n",
    "    for word, count in word_counts.most_common():\n",
    "        if count > 0:\n",
    "            print(k, word, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names = [\"Big Data and programming languages\",\n",
    " \"Python and statistics\",\n",
    " \"databases\",\n",
    " \"machine learning\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hadoop', 'Big Data', 'HBase', 'Java', 'Spark', 'Storm', 'Cassandra']\n",
      "2 : 7 \n",
      "\n",
      "['NoSQL', 'MongoDB', 'Cassandra', 'HBase', 'Postgres']\n",
      "1 : 3 \n",
      "\n",
      "2 : 2 \n",
      "\n",
      "['Python', 'scikit-learn', 'scipy', 'numpy', 'statsmodels', 'pandas']\n",
      "3 : 6 \n",
      "\n",
      "['R', 'Python', 'statistics', 'regression', 'probability']\n",
      "3 : 5 \n",
      "\n",
      "['machine learning', 'regression', 'decision trees', 'libsvm']\n",
      "0 : 3 \n",
      "\n",
      "3 : 1 \n",
      "\n",
      "['Python', 'R', 'Java', 'C++', 'Haskell', 'programming languages']\n",
      "2 : 4 \n",
      "\n",
      "3 : 2 \n",
      "\n",
      "['statistics', 'probability', 'mathematics', 'theory']\n",
      "0 : 2 \n",
      "\n",
      "3 : 2 \n",
      "\n",
      "['machine learning', 'scikit-learn', 'Mahout', 'neural networks']\n",
      "0 : 4 \n",
      "\n",
      "['neural networks', 'deep learning', 'Big Data', 'artificial intelligence']\n",
      "2 : 2 \n",
      "\n",
      "3 : 1 \n",
      "\n",
      "0 : 1 \n",
      "\n",
      "['Hadoop', 'Java', 'MapReduce', 'Big Data']\n",
      "2 : 4 \n",
      "\n",
      "['statistics', 'R', 'statsmodels']\n",
      "3 : 3 \n",
      "\n",
      "['C++', 'deep learning', 'artificial intelligence', 'probability']\n",
      "1 : 2 \n",
      "\n",
      "3 : 2 \n",
      "\n",
      "['pandas', 'R', 'Python']\n",
      "3 : 3 \n",
      "\n",
      "['databases', 'HBase', 'Postgres', 'MySQL', 'MongoDB']\n",
      "1 : 3 \n",
      "\n",
      "2 : 2 \n",
      "\n",
      "['libsvm', 'regression', 'support vector machines']\n",
      "0 : 3 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for document, topic_counts in zip(documents, document_topic_counts):\n",
    "    print(document)\n",
    "    for topic, count in topic_counts.most_common():\n",
    "        if count > 0:\n",
    "            print(topic, ':', count, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'file.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-702c05a3379f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"file.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ing'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'file.txt'"
     ]
    }
   ],
   "source": [
    "for line in open(\"file.txt\"):\n",
    "    for word in line.split():\n",
    "        if word.endswith('ing'):\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "1 + 5 * 2 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-49-c913c1dffb59>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-49-c913c1dffb59>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    1+\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "1+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Moby Dick by Herman Melville 1851>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Sense and Sensibility by Jane Austen 1811>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true contemptible christian abundant few part mean careful puzzled\n",
      "mystifying passing curious loving wise doleful gamesome singular\n",
      "delightfully perilous fearless\n"
     ]
    }
   ],
   "source": [
    "text1.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very so exceedingly heartily a as good great extremely remarkably\n",
      "sweet vast amazingly\n"
     ]
    }
   ],
   "source": [
    "text2.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_pretty am_glad a_lucky is_pretty be_glad\n"
     ]
    }
   ],
   "source": [
    "text2.common_contexts([\"monstrous\", \"very\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text4.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3.generate(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44764"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " ',)',\n",
       " '.',\n",
       " '.)',\n",
       " ':',\n",
       " ';',\n",
       " ';)',\n",
       " '?',\n",
       " '?)',\n",
       " 'A',\n",
       " 'Abel',\n",
       " 'Abelmizraim',\n",
       " 'Abidah',\n",
       " 'Abide',\n",
       " 'Abimael',\n",
       " 'Abimelech',\n",
       " 'Abr',\n",
       " 'Abrah',\n",
       " 'Abraham',\n",
       " 'Abram',\n",
       " 'Accad',\n",
       " 'Achbor',\n",
       " 'Adah',\n",
       " 'Adam',\n",
       " 'Adbeel',\n",
       " 'Admah',\n",
       " 'Adullamite',\n",
       " 'After',\n",
       " 'Aholibamah',\n",
       " 'Ahuzzath',\n",
       " 'Ajah',\n",
       " 'Akan',\n",
       " 'All',\n",
       " 'Allonbachuth',\n",
       " 'Almighty',\n",
       " 'Almodad',\n",
       " 'Also',\n",
       " 'Alvah',\n",
       " 'Alvan',\n",
       " 'Am',\n",
       " 'Amal',\n",
       " 'Amalek',\n",
       " 'Amalekites',\n",
       " 'Ammon',\n",
       " 'Amorite',\n",
       " 'Amorites',\n",
       " 'Amraphel',\n",
       " 'An',\n",
       " 'Anah',\n",
       " 'Anamim',\n",
       " 'And',\n",
       " 'Aner',\n",
       " 'Angel',\n",
       " 'Appoint',\n",
       " 'Aram',\n",
       " 'Aran',\n",
       " 'Ararat',\n",
       " 'Arbah',\n",
       " 'Ard',\n",
       " 'Are',\n",
       " 'Areli',\n",
       " 'Arioch',\n",
       " 'Arise',\n",
       " 'Arkite',\n",
       " 'Arodi',\n",
       " 'Arphaxad',\n",
       " 'Art',\n",
       " 'Arvadite',\n",
       " 'As',\n",
       " 'Asenath',\n",
       " 'Ashbel',\n",
       " 'Asher',\n",
       " 'Ashkenaz',\n",
       " 'Ashteroth',\n",
       " 'Ask',\n",
       " 'Asshur',\n",
       " 'Asshurim',\n",
       " 'Assyr',\n",
       " 'Assyria',\n",
       " 'At',\n",
       " 'Atad',\n",
       " 'Avith',\n",
       " 'Baalhanan',\n",
       " 'Babel',\n",
       " 'Bashemath',\n",
       " 'Be',\n",
       " 'Because',\n",
       " 'Becher',\n",
       " 'Bedad',\n",
       " 'Beeri',\n",
       " 'Beerlahairoi',\n",
       " 'Beersheba',\n",
       " 'Behold',\n",
       " 'Bela',\n",
       " 'Belah',\n",
       " 'Benam',\n",
       " 'Benjamin',\n",
       " 'Beno',\n",
       " 'Beor',\n",
       " 'Bera',\n",
       " 'Bered',\n",
       " 'Beriah',\n",
       " 'Bethel',\n",
       " 'Bethlehem',\n",
       " 'Bethuel',\n",
       " 'Beware',\n",
       " 'Bilhah',\n",
       " 'Bilhan',\n",
       " 'Binding',\n",
       " 'Birsha',\n",
       " 'Bless',\n",
       " 'Blessed',\n",
       " 'Both',\n",
       " 'Bow',\n",
       " 'Bozrah',\n",
       " 'Bring',\n",
       " 'But',\n",
       " 'Buz',\n",
       " 'By',\n",
       " 'Cain',\n",
       " 'Cainan',\n",
       " 'Calah',\n",
       " 'Calneh',\n",
       " 'Can',\n",
       " 'Cana',\n",
       " 'Canaan',\n",
       " 'Canaanite',\n",
       " 'Canaanites',\n",
       " 'Canaanitish',\n",
       " 'Caphtorim',\n",
       " 'Carmi',\n",
       " 'Casluhim',\n",
       " 'Cast',\n",
       " 'Cause',\n",
       " 'Chaldees',\n",
       " 'Chedorlaomer',\n",
       " 'Cheran',\n",
       " 'Cherubims',\n",
       " 'Chesed',\n",
       " 'Chezib',\n",
       " 'Come',\n",
       " 'Cursed',\n",
       " 'Cush',\n",
       " 'Damascus',\n",
       " 'Dan',\n",
       " 'Day',\n",
       " 'Deborah',\n",
       " 'Dedan',\n",
       " 'Deliver',\n",
       " 'Diklah',\n",
       " 'Din',\n",
       " 'Dinah',\n",
       " 'Dinhabah',\n",
       " 'Discern',\n",
       " 'Dishan',\n",
       " 'Dishon',\n",
       " 'Do',\n",
       " 'Dodanim',\n",
       " 'Dothan',\n",
       " 'Drink',\n",
       " 'Duke',\n",
       " 'Dumah',\n",
       " 'Earth',\n",
       " 'Ebal',\n",
       " 'Eber',\n",
       " 'Edar',\n",
       " 'Eden',\n",
       " 'Edom',\n",
       " 'Edomites',\n",
       " 'Egy',\n",
       " 'Egypt',\n",
       " 'Egyptia',\n",
       " 'Egyptian',\n",
       " 'Egyptians',\n",
       " 'Ehi',\n",
       " 'Elah',\n",
       " 'Elam',\n",
       " 'Elbethel',\n",
       " 'Eldaah',\n",
       " 'EleloheIsrael',\n",
       " 'Eliezer',\n",
       " 'Eliphaz',\n",
       " 'Elishah',\n",
       " 'Ellasar',\n",
       " 'Elon',\n",
       " 'Elparan',\n",
       " 'Emins',\n",
       " 'En',\n",
       " 'Enmishpat',\n",
       " 'Eno',\n",
       " 'Enoch',\n",
       " 'Enos',\n",
       " 'Ephah',\n",
       " 'Epher',\n",
       " 'Ephra',\n",
       " 'Ephraim',\n",
       " 'Ephrath',\n",
       " 'Ephron',\n",
       " 'Er',\n",
       " 'Erech',\n",
       " 'Eri',\n",
       " 'Es',\n",
       " 'Esau',\n",
       " 'Escape',\n",
       " 'Esek',\n",
       " 'Eshban',\n",
       " 'Eshcol',\n",
       " 'Ethiopia',\n",
       " 'Euphrat',\n",
       " 'Euphrates',\n",
       " 'Eve',\n",
       " 'Even',\n",
       " 'Every',\n",
       " 'Except',\n",
       " 'Ezbon',\n",
       " 'Ezer',\n",
       " 'Fear',\n",
       " 'Feed',\n",
       " 'Fifteen',\n",
       " 'Fill',\n",
       " 'For',\n",
       " 'Forasmuch',\n",
       " 'Forgive',\n",
       " 'From',\n",
       " 'Fulfil',\n",
       " 'G',\n",
       " 'Gad',\n",
       " 'Gaham',\n",
       " 'Galeed',\n",
       " 'Gatam',\n",
       " 'Gather',\n",
       " 'Gaza',\n",
       " 'Gentiles',\n",
       " 'Gera',\n",
       " 'Gerar',\n",
       " 'Gershon',\n",
       " 'Get',\n",
       " 'Gether',\n",
       " 'Gihon',\n",
       " 'Gilead',\n",
       " 'Girgashites',\n",
       " 'Girgasite',\n",
       " 'Give',\n",
       " 'Go',\n",
       " 'God',\n",
       " 'Gomer',\n",
       " 'Gomorrah',\n",
       " 'Goshen',\n",
       " 'Guni',\n",
       " 'Hadad',\n",
       " 'Hadar',\n",
       " 'Hadoram',\n",
       " 'Hagar',\n",
       " 'Haggi',\n",
       " 'Hai',\n",
       " 'Ham',\n",
       " 'Hamathite',\n",
       " 'Hamor',\n",
       " 'Hamul',\n",
       " 'Hanoch',\n",
       " 'Happy',\n",
       " 'Haran',\n",
       " 'Hast',\n",
       " 'Haste',\n",
       " 'Have',\n",
       " 'Havilah',\n",
       " 'Hazarmaveth',\n",
       " 'Hazezontamar',\n",
       " 'Hazo',\n",
       " 'He',\n",
       " 'Hear',\n",
       " 'Heaven',\n",
       " 'Heber',\n",
       " 'Hebrew',\n",
       " 'Hebrews',\n",
       " 'Hebron',\n",
       " 'Hemam',\n",
       " 'Hemdan',\n",
       " 'Here',\n",
       " 'Hereby',\n",
       " 'Heth',\n",
       " 'Hezron',\n",
       " 'Hiddekel',\n",
       " 'Hinder',\n",
       " 'Hirah',\n",
       " 'His',\n",
       " 'Hitti',\n",
       " 'Hittite',\n",
       " 'Hittites',\n",
       " 'Hivite',\n",
       " 'Hobah',\n",
       " 'Hori',\n",
       " 'Horite',\n",
       " 'Horites',\n",
       " 'How',\n",
       " 'Hul',\n",
       " 'Huppim',\n",
       " 'Husham',\n",
       " 'Hushim',\n",
       " 'Huz',\n",
       " 'I',\n",
       " 'If',\n",
       " 'In',\n",
       " 'Irad',\n",
       " 'Iram',\n",
       " 'Is',\n",
       " 'Isa',\n",
       " 'Isaac',\n",
       " 'Iscah',\n",
       " 'Ishbak',\n",
       " 'Ishmael',\n",
       " 'Ishmeelites',\n",
       " 'Ishuah',\n",
       " 'Isra',\n",
       " 'Israel',\n",
       " 'Issachar',\n",
       " 'Isui',\n",
       " 'It',\n",
       " 'Ithran',\n",
       " 'Jaalam',\n",
       " 'Jabal',\n",
       " 'Jabbok',\n",
       " 'Jac',\n",
       " 'Jachin',\n",
       " 'Jacob',\n",
       " 'Jahleel',\n",
       " 'Jahzeel',\n",
       " 'Jamin',\n",
       " 'Japhe',\n",
       " 'Japheth',\n",
       " 'Jared',\n",
       " 'Javan',\n",
       " 'Jebusite',\n",
       " 'Jebusites',\n",
       " 'Jegarsahadutha',\n",
       " 'Jehovahjireh',\n",
       " 'Jemuel',\n",
       " 'Jerah',\n",
       " 'Jetheth',\n",
       " 'Jetur',\n",
       " 'Jeush',\n",
       " 'Jezer',\n",
       " 'Jidlaph',\n",
       " 'Jimnah',\n",
       " 'Job',\n",
       " 'Jobab',\n",
       " 'Jokshan',\n",
       " 'Joktan',\n",
       " 'Jordan',\n",
       " 'Joseph',\n",
       " 'Jubal',\n",
       " 'Judah',\n",
       " 'Judge',\n",
       " 'Judith',\n",
       " 'Kadesh',\n",
       " 'Kadmonites',\n",
       " 'Karnaim',\n",
       " 'Kedar',\n",
       " 'Kedemah',\n",
       " 'Kemuel',\n",
       " 'Kenaz',\n",
       " 'Kenites',\n",
       " 'Kenizzites',\n",
       " 'Keturah',\n",
       " 'Kiriathaim',\n",
       " 'Kirjatharba',\n",
       " 'Kittim',\n",
       " 'Know',\n",
       " 'Kohath',\n",
       " 'Kor',\n",
       " 'Korah',\n",
       " 'LO',\n",
       " 'LORD',\n",
       " 'Laban',\n",
       " 'Lahairoi',\n",
       " 'Lamech',\n",
       " 'Lasha',\n",
       " 'Lay',\n",
       " 'Leah',\n",
       " 'Lehabim',\n",
       " 'Lest',\n",
       " 'Let',\n",
       " 'Letushim',\n",
       " 'Leummim',\n",
       " 'Levi',\n",
       " 'Lie',\n",
       " 'Lift',\n",
       " 'Lo',\n",
       " 'Look',\n",
       " 'Lot',\n",
       " 'Lotan',\n",
       " 'Lud',\n",
       " 'Ludim',\n",
       " 'Luz',\n",
       " 'Maachah',\n",
       " 'Machir',\n",
       " 'Machpelah',\n",
       " 'Madai',\n",
       " 'Magdiel',\n",
       " 'Magog',\n",
       " 'Mahalaleel',\n",
       " 'Mahalath',\n",
       " 'Mahanaim',\n",
       " 'Make',\n",
       " 'Malchiel',\n",
       " 'Male',\n",
       " 'Mam',\n",
       " 'Mamre',\n",
       " 'Man',\n",
       " 'Manahath',\n",
       " 'Manass',\n",
       " 'Manasseh',\n",
       " 'Mash',\n",
       " 'Masrekah',\n",
       " 'Massa',\n",
       " 'Matred',\n",
       " 'Me',\n",
       " 'Medan',\n",
       " 'Mehetabel',\n",
       " 'Mehujael',\n",
       " 'Melchizedek',\n",
       " 'Merari',\n",
       " 'Mesha',\n",
       " 'Meshech',\n",
       " 'Mesopotamia',\n",
       " 'Methusa',\n",
       " 'Methusael',\n",
       " 'Methuselah',\n",
       " 'Mezahab',\n",
       " 'Mibsam',\n",
       " 'Mibzar',\n",
       " 'Midian',\n",
       " 'Midianites',\n",
       " 'Milcah',\n",
       " 'Mishma',\n",
       " 'Mizpah',\n",
       " 'Mizraim',\n",
       " 'Mizz',\n",
       " 'Moab',\n",
       " 'Moabites',\n",
       " 'Moreh',\n",
       " 'Moreover',\n",
       " 'Moriah',\n",
       " 'Muppim',\n",
       " 'My',\n",
       " 'Naamah',\n",
       " 'Naaman',\n",
       " 'Nahath',\n",
       " 'Nahor',\n",
       " 'Naphish',\n",
       " 'Naphtali',\n",
       " 'Naphtuhim',\n",
       " 'Nay',\n",
       " 'Nebajoth',\n",
       " 'Neither',\n",
       " 'Night',\n",
       " 'Nimrod',\n",
       " 'Nineveh',\n",
       " 'Noah',\n",
       " 'Nod',\n",
       " 'Not',\n",
       " 'Now',\n",
       " 'O',\n",
       " 'Obal',\n",
       " 'Of',\n",
       " 'Oh',\n",
       " 'Ohad',\n",
       " 'Omar',\n",
       " 'On',\n",
       " 'Onam',\n",
       " 'Onan',\n",
       " 'Only',\n",
       " 'Ophir',\n",
       " 'Our',\n",
       " 'Out',\n",
       " 'Padan',\n",
       " 'Padanaram',\n",
       " 'Paran',\n",
       " 'Pass',\n",
       " 'Pathrusim',\n",
       " 'Pau',\n",
       " 'Peace',\n",
       " 'Peleg',\n",
       " 'Peniel',\n",
       " 'Penuel',\n",
       " 'Peradventure',\n",
       " 'Perizzit',\n",
       " 'Perizzite',\n",
       " 'Perizzites',\n",
       " 'Phallu',\n",
       " 'Phara',\n",
       " 'Pharaoh',\n",
       " 'Pharez',\n",
       " 'Phichol',\n",
       " 'Philistim',\n",
       " 'Philistines',\n",
       " 'Phut',\n",
       " 'Phuvah',\n",
       " 'Pildash',\n",
       " 'Pinon',\n",
       " 'Pison',\n",
       " 'Potiphar',\n",
       " 'Potipherah',\n",
       " 'Put',\n",
       " 'Raamah',\n",
       " 'Rachel',\n",
       " 'Rameses',\n",
       " 'Rebek',\n",
       " 'Rebekah',\n",
       " 'Rehoboth',\n",
       " 'Remain',\n",
       " 'Rephaims',\n",
       " 'Resen',\n",
       " 'Return',\n",
       " 'Reu',\n",
       " 'Reub',\n",
       " 'Reuben',\n",
       " 'Reuel',\n",
       " 'Reumah',\n",
       " 'Riphath',\n",
       " 'Rosh',\n",
       " 'Sabtah',\n",
       " 'Sabtech',\n",
       " 'Said',\n",
       " 'Salah',\n",
       " 'Salem',\n",
       " 'Samlah',\n",
       " 'Sarah',\n",
       " 'Sarai',\n",
       " 'Saul',\n",
       " 'Save',\n",
       " 'Say',\n",
       " 'Se',\n",
       " 'Seba',\n",
       " 'See',\n",
       " 'Seeing',\n",
       " 'Seir',\n",
       " 'Sell',\n",
       " 'Send',\n",
       " 'Sephar',\n",
       " 'Serah',\n",
       " 'Sered',\n",
       " 'Serug',\n",
       " 'Set',\n",
       " 'Seth',\n",
       " 'Shalem',\n",
       " 'Shall',\n",
       " 'Shalt',\n",
       " 'Shammah',\n",
       " 'Shaul',\n",
       " 'Shaveh',\n",
       " 'She',\n",
       " 'Sheba',\n",
       " 'Shebah',\n",
       " 'Shechem',\n",
       " 'Shed',\n",
       " 'Shel',\n",
       " 'Shelah',\n",
       " 'Sheleph',\n",
       " 'Shem',\n",
       " 'Shemeber',\n",
       " 'Shepho',\n",
       " 'Shillem',\n",
       " 'Shiloh',\n",
       " 'Shimron',\n",
       " 'Shinab',\n",
       " 'Shinar',\n",
       " 'Shobal',\n",
       " 'Should',\n",
       " 'Shuah',\n",
       " 'Shuni',\n",
       " 'Shur',\n",
       " 'Sichem',\n",
       " 'Siddim',\n",
       " 'Sidon',\n",
       " 'Simeon',\n",
       " 'Sinite',\n",
       " 'Sitnah',\n",
       " 'Slay',\n",
       " 'So',\n",
       " 'Sod',\n",
       " 'Sodom',\n",
       " 'Sojourn',\n",
       " 'Some',\n",
       " 'Spake',\n",
       " 'Speak',\n",
       " 'Spirit',\n",
       " 'Stand',\n",
       " 'Succoth',\n",
       " 'Surely',\n",
       " 'Swear',\n",
       " 'Syrian',\n",
       " 'Take',\n",
       " 'Tamar',\n",
       " 'Tarshish',\n",
       " 'Tebah',\n",
       " 'Tell',\n",
       " 'Tema',\n",
       " 'Teman',\n",
       " 'Temani',\n",
       " 'Terah',\n",
       " 'Thahash',\n",
       " 'That',\n",
       " 'The',\n",
       " 'Then',\n",
       " 'There',\n",
       " 'Therefore',\n",
       " 'These',\n",
       " 'They',\n",
       " 'Thirty',\n",
       " 'This',\n",
       " 'Thorns',\n",
       " 'Thou',\n",
       " 'Thus',\n",
       " 'Thy',\n",
       " 'Tidal',\n",
       " 'Timna',\n",
       " 'Timnah',\n",
       " 'Timnath',\n",
       " 'Tiras',\n",
       " 'To',\n",
       " 'Togarmah',\n",
       " 'Tola',\n",
       " 'Tubal',\n",
       " 'Tubalcain',\n",
       " 'Twelve',\n",
       " 'Two',\n",
       " 'Unstable',\n",
       " 'Until',\n",
       " 'Unto',\n",
       " 'Up',\n",
       " 'Upon',\n",
       " 'Ur',\n",
       " 'Uz',\n",
       " 'Uzal',\n",
       " 'We',\n",
       " 'What',\n",
       " 'When',\n",
       " 'Whence',\n",
       " 'Where',\n",
       " 'Whereas',\n",
       " 'Wherefore',\n",
       " 'Which',\n",
       " 'While',\n",
       " 'Who',\n",
       " 'Whose',\n",
       " 'Whoso',\n",
       " 'Why',\n",
       " 'Wilt',\n",
       " 'With',\n",
       " 'Woman',\n",
       " 'Ye',\n",
       " 'Yea',\n",
       " 'Yet',\n",
       " 'Zaavan',\n",
       " 'Zaphnathpaaneah',\n",
       " 'Zar',\n",
       " 'Zarah',\n",
       " 'Zeboiim',\n",
       " 'Zeboim',\n",
       " 'Zebul',\n",
       " 'Zebulun',\n",
       " 'Zemarite',\n",
       " 'Zepho',\n",
       " 'Zerah',\n",
       " 'Zibeon',\n",
       " 'Zidon',\n",
       " 'Zillah',\n",
       " 'Zilpah',\n",
       " 'Zimran',\n",
       " 'Ziphion',\n",
       " 'Zo',\n",
       " 'Zoar',\n",
       " 'Zohar',\n",
       " 'Zuzims',\n",
       " 'a',\n",
       " 'abated',\n",
       " 'abide',\n",
       " 'able',\n",
       " 'abode',\n",
       " 'abomination',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'absent',\n",
       " 'abundantly',\n",
       " 'accept',\n",
       " 'accepted',\n",
       " 'according',\n",
       " 'acknowledged',\n",
       " 'activity',\n",
       " 'add',\n",
       " 'adder',\n",
       " 'afar',\n",
       " 'afflict',\n",
       " 'affliction',\n",
       " 'afraid',\n",
       " 'after',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'aga',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'aileth',\n",
       " 'air',\n",
       " 'al',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'almon',\n",
       " 'alo',\n",
       " 'alone',\n",
       " 'aloud',\n",
       " 'also',\n",
       " 'altar',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'angel',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angry',\n",
       " 'anguish',\n",
       " 'anointedst',\n",
       " 'anoth',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'any',\n",
       " 'anything',\n",
       " 'appe',\n",
       " 'appear',\n",
       " 'appeared',\n",
       " 'appease',\n",
       " 'appoint',\n",
       " 'appointed',\n",
       " 'aprons',\n",
       " 'archer',\n",
       " 'archers',\n",
       " 'are',\n",
       " 'arise',\n",
       " 'ark',\n",
       " 'armed',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'arose',\n",
       " 'arrayed',\n",
       " 'art',\n",
       " 'artificer',\n",
       " 'as',\n",
       " 'ascending',\n",
       " 'ash',\n",
       " 'ashamed',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asketh',\n",
       " 'ass',\n",
       " 'assembly',\n",
       " 'asses',\n",
       " 'assigned',\n",
       " 'asswaged',\n",
       " 'at',\n",
       " 'attained',\n",
       " 'audience',\n",
       " 'avenged',\n",
       " 'aw',\n",
       " 'awaked',\n",
       " 'away',\n",
       " 'awoke',\n",
       " 'back',\n",
       " 'backward',\n",
       " 'bad',\n",
       " 'bade',\n",
       " 'badest',\n",
       " 'badne',\n",
       " 'bak',\n",
       " 'bake',\n",
       " 'bakemeats',\n",
       " 'baker',\n",
       " 'bakers',\n",
       " 'balm',\n",
       " 'bands',\n",
       " 'bank',\n",
       " 'bare',\n",
       " 'barr',\n",
       " 'barren',\n",
       " 'basket',\n",
       " 'baskets',\n",
       " 'battle',\n",
       " 'bdellium',\n",
       " 'be',\n",
       " 'bear',\n",
       " 'beari',\n",
       " 'bearing',\n",
       " 'beast',\n",
       " 'beasts',\n",
       " 'beautiful',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'bed',\n",
       " 'been',\n",
       " 'befall',\n",
       " 'befell',\n",
       " 'before',\n",
       " 'began',\n",
       " 'begat',\n",
       " 'beget',\n",
       " 'begettest',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begotten',\n",
       " 'beguiled',\n",
       " 'beheld',\n",
       " 'behind',\n",
       " 'behold',\n",
       " 'being',\n",
       " 'believed',\n",
       " 'belly',\n",
       " 'belong',\n",
       " 'beneath',\n",
       " 'bereaved',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'besought',\n",
       " 'best',\n",
       " 'betimes',\n",
       " 'better',\n",
       " 'between',\n",
       " 'betwixt',\n",
       " 'beyond',\n",
       " 'binding',\n",
       " 'bird',\n",
       " 'birds',\n",
       " 'birthday',\n",
       " 'birthright',\n",
       " 'biteth',\n",
       " 'bitter',\n",
       " 'blame',\n",
       " 'blameless',\n",
       " 'blasted',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blesseth',\n",
       " 'blessi',\n",
       " 'blessing',\n",
       " 'blessings',\n",
       " 'blindness',\n",
       " 'blood',\n",
       " 'blossoms',\n",
       " 'bodies',\n",
       " 'boldly',\n",
       " 'bondman',\n",
       " 'bondmen',\n",
       " 'bondwoman',\n",
       " 'bone',\n",
       " 'bones',\n",
       " 'book',\n",
       " 'booths',\n",
       " 'border',\n",
       " 'borders',\n",
       " 'born',\n",
       " 'bosom',\n",
       " 'both',\n",
       " 'bottle',\n",
       " 'bou',\n",
       " 'boug',\n",
       " 'bough',\n",
       " 'bought',\n",
       " 'bound',\n",
       " 'bow',\n",
       " 'bowed',\n",
       " 'bowels',\n",
       " 'bowing',\n",
       " 'boys',\n",
       " 'bracelets',\n",
       " 'branches',\n",
       " 'brass',\n",
       " 'bre',\n",
       " 'breach',\n",
       " 'bread',\n",
       " 'breadth',\n",
       " 'break',\n",
       " 'breaketh',\n",
       " 'breaking',\n",
       " 'breasts',\n",
       " 'breath',\n",
       " 'breathed',\n",
       " 'breed',\n",
       " 'brethren',\n",
       " 'brick',\n",
       " 'brimstone',\n",
       " 'bring',\n",
       " 'brink',\n",
       " 'broken',\n",
       " 'brook',\n",
       " 'broth',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'bruise',\n",
       " 'budded',\n",
       " 'build',\n",
       " 'builded',\n",
       " 'built',\n",
       " 'bulls',\n",
       " 'bundle',\n",
       " 'bundles',\n",
       " 'burdens',\n",
       " 'buried',\n",
       " 'burn',\n",
       " 'burning',\n",
       " 'burnt',\n",
       " 'bury',\n",
       " 'buryingplace',\n",
       " 'business',\n",
       " 'but',\n",
       " 'butler',\n",
       " 'butlers',\n",
       " 'butlership',\n",
       " 'butter',\n",
       " 'buy',\n",
       " 'by',\n",
       " 'cakes',\n",
       " 'calf',\n",
       " 'call',\n",
       " 'called',\n",
       " 'came',\n",
       " 'camel',\n",
       " 'camels',\n",
       " 'camest',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'canst',\n",
       " 'captain',\n",
       " 'captive',\n",
       " 'captives',\n",
       " 'carcases',\n",
       " 'carried',\n",
       " 'carry',\n",
       " 'cast',\n",
       " 'castles',\n",
       " 'catt',\n",
       " 'cattle',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'cave',\n",
       " 'cease',\n",
       " 'ceased',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chain',\n",
       " 'chamber',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'chariot',\n",
       " 'chariots',\n",
       " 'chesnut',\n",
       " 'chi',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'childless',\n",
       " 'childr',\n",
       " 'children',\n",
       " 'chode',\n",
       " 'choice',\n",
       " 'chose',\n",
       " 'circumcis',\n",
       " 'circumcise',\n",
       " 'circumcised',\n",
       " 'citi',\n",
       " 'cities',\n",
       " 'city',\n",
       " 'clave',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'cleave',\n",
       " 'clo',\n",
       " 'closed',\n",
       " 'clothed',\n",
       " 'clothes',\n",
       " 'cloud',\n",
       " 'clusters',\n",
       " 'co',\n",
       " 'coat',\n",
       " 'coats',\n",
       " 'coffin',\n",
       " 'cold',\n",
       " ...]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2789"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06230453042623537"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text3)) / len(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3.count(\"smote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4643016433938312"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * text4.count('a') / len(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage(count, total):\n",
    "    return 100 * count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06230453042623537"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13477005109975562"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4643016433938312"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage(text4.count('a'), len(text4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
